# Algebra Optimization Implementation Summary

## Changes Made

### 1. Model Switch: Llama-3.2-3B â†’ Qwen3-4B
- Updated MODEL_NAME in pipeline.py to "Qwen/Qwen3-4B-Instruct"
- Qwen models typically have better mathematical reasoning capabilities
- Maintains good latency while hopefully improving accuracy

### 2. Enhanced Algebra Prompt Engineering
- Replaced the previous algebra prompt with a structured format:
  - PROBLEM: [original question]
  - THINKING: Step-by-step analysis
  - FORMULA: Appropriate mathematical method
  - CALCULATION: Detailed steps
  - ANSWER: Final result
- This structured approach forces the model to think through problems methodically
- Added knowledge base context to reinforce mathematical concepts

### 3. Optimized Sampling Parameters for Qwen3-4B
- Lower temperature (0.05) for more deterministic mathematical results
- Lower top_k (20) for more consistent responses
- Increased max_tokens (1000) to allow for detailed step-by-step solutions
- Updated stop tokens to match new prompt structure

### 4. Updated Documentation
- README.md updated to reflect Qwen3-4B usage and structured approach
- Changed focus from calculator to structured reasoning

## Expected Impact
- Better mathematical reasoning from Qwen3-4B model
- More consistent and accurate algebra solutions due to structured prompting
- Reduced "stupid stuff" by requiring step-by-step reasoning
- Hopefully better scores on algebra problems leading to overall ranking improvement

## Files Modified
- inferencePipeline/pipeline.py: Main implementation
- README.md: Documentation update
- requirements.txt: Added Qwen dependency
- ALGEBRA_OPTIMIZATION.md: Strategy document